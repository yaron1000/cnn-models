{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras with TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Environment\n",
    "\n",
    "We begin by importing a number of useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Earth Engine client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earth Engine data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central position of (AOIs)\n",
    "points = [[-120.7224, 37.3872], [-112.6799, 42.9816], [-89.7649, 35.8764], \n",
    "          [-96.0181, 41.2412], [-115.473, 46.861], [-103.9803, 47.9713], \n",
    "          [-96.9217, 32.8958], [-82.986, 40.019], [-90.347, 38.668], \n",
    "          [-110.6947, 37.4568], [-101.8889, 33.5527], [-92.621, 33.417],\n",
    "          [-80.352, 38.628], [-104.752, 43.972], [-110.92, 37.18]]\n",
    "\n",
    "# Start and stop of time series\n",
    "startDate = ee.Date('2016-01-01')\n",
    "stopDate  = ee.Date('2016-12-31')\n",
    "# Scale in meters\n",
    "scale = 10\n",
    "# Buffer\n",
    "buffer = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocess.ee_dataset_acquisition_TFRecord import ee_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export `.TFRecord` files to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ee_dataset(points = points, buffer = buffer, startDate = startDate, stopDate = stopDate, \n",
    "                  scale = scale, patch_size = [256,256], file_name='AOI_TFRecord', \n",
    "                  collections = ['Sentinel2', 'CroplandDataLayers'])\n",
    "data.export_toCloudStorage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read `.tfrecord` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "bucketname = 'skydipper_materials'\n",
    "bucket = client.get_bucket(bucketname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the list of files in the bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'gee_data_TFRecords/'\n",
    "file_type = 'tfrecord.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "blobs = bucket.list_blobs(prefix=folder)\n",
    "for blob in blobs:\n",
    "    filelist.append(blob.name)   \n",
    "\n",
    "files = [i for i in filelist if file_type in i]\n",
    "files = ['gs://'+bucketname+'/'+i for i in files]\n",
    "\n",
    "files_json = [i for i in filelist if 'json' in i]\n",
    "files_json = ['gs://'+bucketname+'/'+i for i in files_json]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = files[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRecords = 0\n",
    "options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "for file in files:\n",
    "    print(file)\n",
    "    for record in tf.python_io.tf_record_iterator(file, options=options):\n",
    "    \n",
    "        nRecords += 1\n",
    "\n",
    "print('Number of Records:', nRecords)\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(record) # calling protocol buffer API\n",
    "\n",
    "#image_B8 = np.array(example.features.feature['B8'].float_list.value).reshape(256,256)\n",
    "bands = ['B2', 'B3', 'B4', 'B8', 'ndvi', 'ndwi']\n",
    "image = np.concatenate([np.array(example.features.feature[i].float_list.value).reshape(256,256,1) for i in bands], axis=2)\n",
    "\n",
    "band_cropland = example.features.feature['cropland'].bytes_list.value[0]\n",
    "tensor_cropland = tf.reshape(tf.decode_raw(band_cropland, tf.uint8), [256,256])\n",
    "\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    image_cropland = tensor_cropland.eval()\n",
    "    \n",
    "fig, ax = plt.subplots(1,len(bands), figsize=(5*len(bands),5))\n",
    "for i in range(len(bands)):\n",
    "    ax[i].imshow(image[:,:,i])\n",
    "    \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image_cropland);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tf.data.Dataset from `TFRecord` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(proto):\n",
    "    \n",
    "    # Define your tfrecord \n",
    "    bands_input = ['B2', 'B3', 'B4', 'B8', 'ndvi', 'ndwi']\n",
    "    columns_input = [tf.FixedLenFeature([256,256,1], tf.float32) for i in bands_input]\n",
    "\n",
    "    bands_output = ['cropland']\n",
    "    columns_output = [tf.FixedLenFeature([], tf.string) for i in bands_output]\n",
    "\n",
    "    bands = bands_input + bands_output\n",
    "    columns = columns_input + columns_output\n",
    "    features = dict(zip(bands, columns))\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.parse_single_example(proto, features)\n",
    "    \n",
    "    # Separate the output images from the input images\n",
    "    label = parsed_features.pop('cropland')\n",
    "    image = tf.concat([parsed_features[i] for i in bands_input], axis=2)\n",
    "    \n",
    "    # Turn your saved image string into an array\n",
    "    label = tf.decode_raw(label, tf.uint8)\n",
    "    \n",
    "    # Normalize\n",
    "    image = tf.divide(image, 255.0)\n",
    "    \n",
    "    # Bring your picture back in shape\n",
    "    label = tf.reshape(label, [256, 256])\n",
    "    \n",
    "    # Create a one hot array for your labels\n",
    "    label = tf.one_hot(label, 4)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filepath, shuffleSize, batchSize, nEpochs, nRecords, split=None):\n",
    "    \n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filepath, compression_type='GZIP')\n",
    "    \n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat(nEpochs)\n",
    "    \n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=8)\n",
    "    \n",
    "    # Set the number of datapoints you want to load and shuffle \n",
    "    #if shuffleSize:\n",
    "    #    dataset = dataset.shuffle(shuffleSize)\n",
    "    \n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(batchSize)\n",
    "    \n",
    "    # Split dataset into training and validation\n",
    "    if split:\n",
    "        train_size = int(0.7 * nRecords)\n",
    "        val_size = int(0.3 * nRecords)\n",
    "        \n",
    "        train_dataset = dataset.take(train_size)\n",
    "        val_dataset = dataset.skip(train_size)\n",
    "        val_dataset = val_dataset.take(val_size)\n",
    "        \n",
    "        # Create an iterators\n",
    "        train_iterator = train_dataset.make_one_shot_iterator()\n",
    "        val_iterator = val_dataset.make_one_shot_iterator()\n",
    "        \n",
    "        return train_iterator, val_iterator\n",
    "    \n",
    "    else:\n",
    "        # Create an iterator\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "        return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(filepath=files, shuffleSize=nRecords, batchSize=4, \n",
    "                         nEpochs=1, nRecords=nRecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = create_dataset(filepath=files, shuffleSize=nRecords, batchSize=4, \n",
    "                                             nEpochs=1, nRecords=nRecords, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_dataset.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = val_dataset.get_next()\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    label = label.eval()\n",
    "    image = image.eval()\n",
    "    \n",
    "fig, ax = plt.subplots(1, 6, figsize=(30,5))\n",
    "for i in range(6):\n",
    "    ax[i].imshow(image[0,:,:,i])\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20,5))\n",
    "for i in range(4):\n",
    "    ax[i].imshow(label[0,:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset.get_next()\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    label = label.eval()\n",
    "    image = image.eval()\n",
    "    \n",
    "fig, ax = plt.subplots(1, 6, figsize=(30,5))\n",
    "for i in range(6):\n",
    "    ax[i].imshow(image[0,:,:,i])\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20,5))\n",
    "for i in range(4):\n",
    "    ax[i].imshow(label[0,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Model\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers.core import Layer, Activation, Reshape, Permute\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.python.keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segnet(inputShape, nClasses):\n",
    "    \"\"\"\n",
    "    SegNet model\n",
    "    ----------\n",
    "    inputShape : tuple\n",
    "        Tuple with the dimensions of the input data (ny, nx, nBands). \n",
    "    nClasses : int\n",
    "         Number of classes.\n",
    "    \"\"\"\n",
    "\n",
    "    filter_size = 64\n",
    "    kernel = (3, 3)        \n",
    "    pad = (1, 1)\n",
    "    pool_size = (2, 2)\n",
    "        \n",
    "\n",
    "    inputs = Input(shape=inputShape)\n",
    "        \n",
    "    # Encoder\n",
    "    x = Conv2D(64, kernel, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "            \n",
    "    x = Conv2D(128, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "            \n",
    "    x = Conv2D(256, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "            \n",
    "    x = Conv2D(512, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "    # Decoder\n",
    "    x = Conv2D(512, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=pool_size)(x)\n",
    "            \n",
    "    x = Conv2D(256, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=pool_size)(x)\n",
    "            \n",
    "    x = Conv2D(128, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D(size=pool_size)(x)\n",
    "            \n",
    "    x = Conv2D(64, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "            \n",
    "    x = Conv2D(nClasses, (1, 1), padding='valid')(x)\n",
    "    \n",
    "    outputs = Activation('softmax')(x)\n",
    "        \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='segnet')\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segnet(inputShape=(256, 256, 6), nClasses=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs = 1\n",
    "batchSize = 4\n",
    "nStep = int(nRecords/batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=nEpochs, steps_per_epoch=nStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['gs://skydipper_materials/gee_data/AOI_TFRecord_test_00.tfrecord.gz']\n",
    "options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "\n",
    "nRecords = 0\n",
    "for file in files:\n",
    "    for record in tf.python_io.tf_record_iterator(file, options=options):\n",
    "        nRecords += 1\n",
    "\n",
    "print('Number of Records:', nRecords)\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(record) # calling protocol buffer API\n",
    "\n",
    "image_B8 = np.array(example.features.feature['B8'].float_list.value).reshape(256,256)\n",
    "\n",
    "band_cropland = example.features.feature['cropland'].bytes_list.value[0]\n",
    "tensor_cropland = tf.reshape(tf.decode_raw(band_cropland, tf.uint8), [256,256])\n",
    "\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    image_cropland = tensor_cropland.eval()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "ax[0].imshow(image_cropland)\n",
    "ax[1].imshow(image_B8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = create_dataset(filepath=files, shuffleSize=None, batchSize=4, nEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 4\n",
    "nStep = int(nRecords/batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_out = model.predict(dataset_val, steps=nStep, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20,5))\n",
    "for i in range(4):\n",
    "    ax[i].imshow(dataset_out[0,:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
